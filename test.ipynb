{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from models import bird_model, load_regressor\n",
    "from utils.vis_bird import render_sample, render_sample_new\n",
    "from datasets import Cowbird_Dataset\n",
    "from keypoint_detection import load_detector, postprocess\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird = bird_model()\n",
    "regressor = load_regressor().to(device)\n",
    "predictor = load_detector().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229])\n",
    "        ])\n",
    "unnormalize = T.Compose([\n",
    "    T.Normalize(mean=[0, 0, 0], std=[1/0.225, 1/0.224, 1/0.229]),\n",
    "    T.Normalize(mean=[-0.406, -0.456, -0.485], std=[1, 1, 1])\n",
    "    ])\n",
    "valid_set = Cowbird_Dataset('data/cowbird/images', 'data/cowbird/annotations/instance_test.json', transform=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "trans = []\n",
    "bones = []\n",
    "for i in range(len(valid_set)):\n",
    "    imgs, target_kpts, target_masks, meta = valid_set[i]\n",
    "    imgs = imgs[None]\n",
    "    with torch.no_grad():\n",
    "        # Prediction\n",
    "        output = predictor(imgs.to(device))\n",
    "        pred_kpts, pred_mask = postprocess(output)\n",
    "        print(pred_kpts)\n",
    "        print(pred_kpts.shape)\n",
    "        # Regression\n",
    "        kpts_in = pred_kpts.reshape(pred_kpts.shape[0], -1)\n",
    "        print(kpts_in.shape)\n",
    "        mask_in = pred_mask\n",
    "        p_est, b_est = regressor(kpts_in, mask_in)\n",
    "        print(p_est.shape, b_est.shape)\n",
    "        pose, tran, bone = regressor.postprocess(p_est, b_est)\n",
    "        poses.append(p_est.squeeze().cpu().numpy())\n",
    "        # trans.append(tran.squeeze().cpu().numpy())\n",
    "        bones.append(b_est.squeeze().cpu().numpy())\n",
    "        # print(pose.shape, tran.shape, bone.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian to pose\n",
    "# Noise to bone\n",
    "\n",
    "\"\"\"\n",
    "we fit a\n",
    "multivariate Gaussian to the estimated pose parameters (pose, viewpoint, and\n",
    "translation). We then sample 100 random points from this distribution for each\n",
    "bird instance, project the corresponding model's visible keypoints onto the camera \n",
    "and render the silhouette, generating 14,000 synthetic instances for training.\n",
    "We keep the bone lengths of the original 140 instances, but add in random noise\n",
    "to the bone lengths for each sample.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = np.asarray(poses)\n",
    "bones = np.asarray(bones)\n",
    "\n",
    "poses.shape, bones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, mixture\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "i_s = []\n",
    "mu = np.average(poses, axis=0)\n",
    "for i in range(2, 114):\n",
    "    pca = decomposition.PCA(n_components=i)\n",
    "    poses_pca = pca.fit(poses)\n",
    "    nComp = i\n",
    "    Xhat = np.dot(pca.transform(poses)[:,:nComp], pca.components_[:nComp,:])\n",
    "    Xhat += mu\n",
    "    # print(Xhat.shape, poses.shape)\n",
    "    loss = np.sum(np.abs(poses - Xhat) ** 2)\n",
    "    losses.append(loss)\n",
    "    i_s.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(i_s, losses)\n",
    "print(losses[19], losses[39], losses[79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "mu, cov = np.mean(poses, axis=0), np.cov(poses, rowvar=0)\n",
    "print(mu.shape, cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "sample = np.random.multivariate_normal(mu, cov, size=100000)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_bone = np.mean(bones, axis=0)\n",
    "print(mu_bone.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import bird_model, load_regressor\n",
    "from utils.vis_bird import render_sample, render_sample_new\n",
    "from optimization import OptimizeSV, base_renderer\n",
    "sample = np.random.multivariate_normal(mu, cov, size=1)\n",
    "p_est = sample[0][None,:]\n",
    "b_est = (bones[0] + np.random.normal(loc=0, size=(24), scale=0.2))[None,:]\n",
    "print(p_est.shape, b_est.shape)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "bird = bird_model()\n",
    "\n",
    "p_est = torch.from_numpy(p_est)\n",
    "b_est = torch.from_numpy(b_est)\n",
    "\n",
    "pose, tran, bone = regressor.postprocess(p_est, b_est)\n",
    "print(pose.shape, tran.shape, bone.shape)\n",
    "\n",
    "optimizer = OptimizeSV(num_iters=0, prior_weight=1, mask_weight=1, \n",
    "                               use_mask=False, device=device)\n",
    "\n",
    "global_t = tran.clone()\n",
    "bone_length = bone.clone()\n",
    "\n",
    "init_pose = optimizer.transform_p(pose)\n",
    "global_orient = init_pose.clone()[:, :3]\n",
    "body_pose = init_pose.clone()[:, 3:]\n",
    "\n",
    "bird_output = bird(global_orient, body_pose, bone_length)\n",
    "global_txyz = optimizer.transform_t(global_t)\n",
    "\n",
    "model_mesh = bird_output['vertices'] + global_txyz.unsqueeze(1).to(torch.float)\n",
    "\n",
    "# print(bird_output.shape)\n",
    "\n",
    "img_opt, mask = render_sample_new(bird, model_mesh[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_txyz.unsqueeze(1).to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bird_output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bird_output['keypoints'] + global_txyz.unsqueeze(1).to(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.renderer_p3d import RendererP3D\n",
    "\n",
    "kps = bird_output['keypoints'] + global_txyz.unsqueeze(1).to(torch.float)\n",
    "\n",
    "render = RendererP3D(faces=bird.dd['F'])\n",
    "cameras = render.cameras\n",
    "\n",
    "from utils.geometry import perspective_projection\n",
    "\n",
    "print(cameras.get_projection_transform().transform_points(kps))\n",
    "\n",
    "proj_kps = perspective_projection(kps, None, None, 2167, 128, None)\n",
    "print(proj_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_opt)\n",
    "plt.scatter(proj_kps.squeeze()[:,0], proj_kps.squeeze()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "from utils.img_utils import draw_kpts\n",
    "# for i in range(len(valid_set)):\n",
    "# 8, 20, 24, 29!\n",
    "i = 0\n",
    "imgs, target_kpts, target_masks, meta = valid_set[i]\n",
    "imgs = unnormalize(imgs)\n",
    "imgs = F.to_pil_image(imgs)\n",
    "plt.imshow(imgs)\n",
    "plt.scatter(target_kpts[:, 0], target_kpts[:, 1], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.syn_dataset import synDataset\n",
    "train_set = Cowbird_Dataset('data/cowbird/images', 'data/cowbird/annotations/instance_train.json', transform=normalize)\n",
    "syn_dataset = synDataset(train_set)\n",
    "\n",
    "syn_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_int = syn_dataset[0]\n",
    "# plt.scatter(test_int[2][:, 0], test_int[2][:, 1], c='red')\n",
    "# plt.imshow(test_int[0])\n",
    "# print(syn_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_int = syn_dataset[0]\n",
    "# plt.scatter(test_int[2][:, 0], test_int[2][:, 1], c='red')\n",
    "# plt.imshow(test_int[0])\n",
    "# print(syn_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model loss and training process.\n",
    "from models.mesh_regressor import mesh_regressor\n",
    "\n",
    "model = mesh_regressor()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "dataloader = torch.utils.data.DataLoader(syn_dataset, 16, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model = model.cuda()\n",
    "model.train()\n",
    "\n",
    "loss_total = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        _, mask, kps, p_gt, b_gt = data\n",
    "        \n",
    "        mask = mask.cuda()\n",
    "        kps = kps.cuda()\n",
    "        p_gt = p_gt.cuda()\n",
    "        b_gt = b_gt.cuda()\n",
    "\n",
    "        # print(mask.shape, kps.shape, p_gt.shape, b_gt.shape)\n",
    "\n",
    "        pose_tran, bone = model(kps, mask)\n",
    "        # print(pose_tran.shape, bone.shape)\n",
    "        loss = loss_fn(pose_tran, p_gt) + loss_fn(bone, b_gt)\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    batch_loss = loss_total / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}: {batch_loss}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./{epoch+1}.pth\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0f2db70cdb2a412572c38a53b7aaca03d291072e5f638ff17441842cf0de682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
